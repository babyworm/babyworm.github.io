---
title: 결국 다음 봇 차단 결정
author: babyworm
type: post
date: 2006-11-14T10:45:29+00:00
categories:
  - 개인적인
tags:
  - robots.txt
  - 다음봇
  - 로봇

---
트래픽을 몰리는 원인 분석 결과.. 가장 큰 원인이 여러개의 다음 봇이 동시에 접근하고 있는 것을 발견했습니다.  
제가 알기로 다음봇은 구글봇과 동일해서 robots.txt 규칙을 잘 지키는 것으로 알고 있었는데.. 

어쩐 일인지, 여러개의 로봇이 돌아가면서 접근해서 엄청나게 트래픽을 잡아먹네요..  
robots.txt 규칙을 따른다면 여러 봇이 오더라도 3시간에 한번씩만 가져가야 하니.. 트래픽이 많이 걸리지 않을 듯 한데.. 제가 뭔가 잘못 생각한 것인지도..

여하튼.. 이런 저런 생각하기 싫어서 .htaccess 에서 다음봇에 해당하는 영역을 그냥 deny했습니다. 

트래픽이 아마 다시 30%대로 떨어져주지 않을까 기대됩니다. 

다음봇.. 너무합니다.